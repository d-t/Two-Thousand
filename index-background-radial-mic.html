<!DOCTYPE html>
<html lang="en-US">

<head>
    <title>2000</title>
    <meta name="author" content="Luca Murgia">
    <meta name="keywords" content="2000, Two Thousand, Music, Future">
    <meta name="description" content="Two Thousand is a faded idea of the future.">
    <meta charset="UTF-8">
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="style-bg.css">
</head>


<body>
    <h1><b>Two Thousand</b></h1>
    <p>Two Thousand is a faded idea of the future. </p>
    <canvas id="future-pro" width="800" height="400"></canvas>
    <audio id="player"></audio>
</body>

<script type="text/javascript">

// Hack to handle vendor prefixes
navigator.getUserMedia = ( navigator.getUserMedia ||
                           navigator.webkitGetUserMedia ||
                           navigator.mozGetUserMedia ||
                           navigator.msGetUserMedia);

window.requestAnimFrame = (function(){
  return  window.requestAnimationFrame       ||
          window.webkitRequestAnimationFrame ||
          window.mozRequestAnimationFrame    ||
          function(callback, element){
            window.setTimeout(callback, 1000 / 60);
          };
})();

window.AudioContext = (function(){
    return  window.webkitAudioContext || window.AudioContext || window.mozAudioContext;
})();

// Global Variables for Audio
var audioContext;
var analyserNode;
var javascriptNode;
var sampleSize = 1024;  // number of samples to collect before analyzing
                        // decreasing this gives a faster sonogram, increasing it slows it down
var amplitudeArray;     // array to hold frequency data
var audioStream;

// Implementation
var canvas = document.getElementById("future-pro");
var context = canvas.getContext("2d");
// ctx = $("#future-pro").get()[0].getContext("2d");
try {
    audioContext = new AudioContext();
} catch(e) {
    alert('Web Audio API is not supported in this browser');
}
// get the input audio stream and set up the nodes
try {
    navigator.getUserMedia(
      { video: false,
        audio: true},
      setupAudioNodes,
      onError);
} catch (e) {
    alert('webkitGetUserMedia threw exception :' + e);
}

function setupAudioNodes(stream) {
    // create the media stream from the audio input source (microphone)
    sourceNode = audioContext.createMediaStreamSource(stream);
    audioStream = stream;

    analyserNode   = audioContext.createAnalyser();
    javascriptNode = audioContext.createScriptProcessor(sampleSize, 1, 1);

    // Create the array for the data values
    amplitudeArray = new Uint8Array(analyserNode.frequencyBinCount);

    // setup the event handler that is triggered every time enough samples have been collected
    // trigger the audio analysis and draw one column in the display based on the results
    javascriptNode.onaudioprocess = function () {

        amplitudeArray = new Uint8Array(analyserNode.frequencyBinCount);
        analyserNode.getByteTimeDomainData(amplitudeArray);

        // draw one column of the display
        requestAnimFrame(drawTimeDomain);
    }

    // Now connect the nodes together
    // Do not connect source node to destination - to avoid feedback
    sourceNode.connect(analyserNode);
    analyserNode.connect(javascriptNode);
    javascriptNode.connect(audioContext.destination);
}

function onError(e) {
    console.log(e);
}

function drawTimeDomain() {
    var audioImage = new Image();
    audioImage.onload = function() {
        context.drawImage(this, 0, 0);
        if (this.naturalWidth > 0){
            var width = this.naturalWidth;
            var height = this.naturalHeight;

            var alpha = 0.45;

            for (x = 0; x < width/2; x++) {  // for each column...
                if (x < amplitudeArray.length) {
                    val = amplitudeArray[x];
                    // val = audioSource.streamData[width/2 - x + 1];
                }
                else {
                    val = 1;
                }
                // Draw circle
                red = val / 2;
                green = val / 2;
                blue = val / 8;

                context.beginPath();
                context.arc(width/2, height/2, x, 0, 2 * Math.PI, false);
                context.strokeStyle = 'rgba(' + red + ', ' + green + ', ' + blue + ', ' + alpha + ')';
                context.lineWidth = 1;
                context.stroke();
            }//for
        }//if
    };
    audioImage.src = "media/future-pro.png";


    // console.log(amplitudeArray[555]);
}

</script>